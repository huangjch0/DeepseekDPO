# DeepSeek V3 DPO 训练配置

# 模型配置
model_name: "deepseek-ai/deepseek-llm-7b-base"

# 数据配置
train_data_path: "./data/dpo_train_data.json"
val_data_path: "./data/dpo_val_data.json"

# 训练配置
num_epochs: 3
batch_size: 8
learning_rate: 0.0001
beta: 0.5
max_length: 2048

# 数据加载配置
num_workers: 4

# 优化器配置
weight_decay: 0.01
warmup_steps: 500

# 评估和保存配置
eval_steps: 100
save_steps: 500
output_dir: "./output/dpo_model"

# 设备配置
device: "cuda"


lora:
  enabled: true
  r: 16
  alpha: 32
  dropout: 0.05
  # 按你的基座模型结构选择模块名（下例适用于 LLaMA 系）
  target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]